from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from typing import Annotated, Literal
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, ToolMessage
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import interrupt, Command
import os

load_dotenv()


def create_agent():
    memory = MemorySaver()

    # Stateå‹ã®å®šç¾©
    class State(TypedDict):
        messages: Annotated[list[BaseMessage], add_messages]

    # ãƒ„ãƒ¼ãƒ«ã®è¨­å®š
    @tool
    def today_weather(place: str) -> str:
        """ä»Šæ—¥ã®å¤©æ°—äºˆå ±ã‚’è¿”ã—ã¾ã™"""
        print(f"ğŸ” {place}ã®å¤©æ°—ã‚’ç¢ºèªä¸­...")
        return "æ™´ã‚Œ"

    tool_list = [today_weather]
    llm = ChatAnthropic(
        api_key=os.getenv("ANTHROPIC_API_KEY"), model="claude-3-5-sonnet-20240620"
    ).bind_tools(tool_list)

    # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé–¢æ•°
    def chatbot(state: State):
        return {"messages": [llm.invoke(state["messages"])]}

    # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå‰ã®ç¢ºèªãƒãƒ¼ãƒ‰
    def human_review(state: State) -> Command[Literal["chatbot", "tools"]]:
        last_message = state["messages"][-1]
        tool_call = last_message.tool_calls[-1]

        # äººé–“ã«ç¢ºèªã‚’æ±‚ã‚ã‚‹
        review = interrupt({
            "question": "å¤©æ°—ç¢ºèªã®å®Ÿè¡Œç¢ºèª",
            "tool_call": tool_call,
            "options": ["å®Ÿè¡Œ", "ç·¨é›†", "ã‚­ãƒ£ãƒ³ã‚»ãƒ«"]
        })

        action = review.get("action")
        data = review.get("data")

        if action == "continue":
            return Command(goto="tools")

        elif action == "update":
            updated_message = {
                "role": "ai",
                "content": last_message.content,
                "tool_calls": [{
                    "id": tool_call["id"],
                    "name": tool_call["name"],
                    "args": data,
                }],
                "id": last_message.id
            }
            return Command(goto="tools", update={"messages": [updated_message]})

        else:  # cancel
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚’ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã—ã¦å‡¦ç†
            tool_message = {
                "role": "tool",
                "content": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¤©æ°—ç¢ºèªã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚",
                "name": tool_call["name"],
                "tool_call_id": tool_call["id"],
            }
            return Command(goto="chatbot", update={"messages": [tool_message]})

    def route_after_llm(state) -> Literal["human_review", END]:
        if len(state["messages"][-1].tool_calls) == 0:
            return END
        return "human_review"

    # ã‚°ãƒ©ãƒ•ã®è¨­å®š
    builder = StateGraph(State)
    builder.add_node("chatbot", chatbot)
    builder.add_node("tools", ToolNode(tools=tool_list))
    builder.add_node("human_review", human_review)
    builder.set_entry_point("chatbot")

    builder.add_conditional_edges("chatbot", route_after_llm)
    builder.add_edge("tools", "chatbot")
    builder.add_edge("human_review", "tools")

    return builder.compile(
        checkpointer=memory,
    )
